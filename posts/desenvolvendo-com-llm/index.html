<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Desenvolvendo Software com assistência de LLM - Alen Vieira</title><meta name=viewport content="width=device-width,initial-scale=1">
<meta itemprop=name content="Desenvolvendo Software com assistência de LLM"><meta itemprop=description content="Que tal desenvolvemos software com ajuda de uma IA?"><meta itemprop=datePublished content="2024-01-30T16:40:49-03:00"><meta itemprop=dateModified content="2024-01-30T16:40:49-03:00"><meta itemprop=wordCount content="483"><meta itemprop=keywords content><meta property="og:title" content="Desenvolvendo Software com assistência de LLM"><meta property="og:description" content="Que tal desenvolvemos software com ajuda de uma IA?"><meta property="og:type" content="article"><meta property="og:url" content="https://alenvieira.github.io/posts/desenvolvendo-com-llm/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-30T16:40:49-03:00"><meta property="article:modified_time" content="2024-01-30T16:40:49-03:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Desenvolvendo Software com assistência de LLM"><meta name=twitter:description content="Que tal desenvolvemos software com ajuda de uma IA?"><link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel=stylesheet type=text/css><link rel=stylesheet type=text/css media=screen href=https://alenvieira.github.io/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://alenvieira.github.io/css/main.css><link id=dark-scheme rel=stylesheet type=text/css href=https://alenvieira.github.io/css/dark.css><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script><script src=https://alenvieira.github.io/js/main.js></script></head><body><div class="container wrapper"><div class=header><h1 class=site-title><a href=https://alenvieira.github.io/>Alen Vieira</a></h1><div class=site-description><p>Compartilhando ou documentando questões</p><nav class="nav social"><ul class=flat><li><a href=https://github.com/alenvieira title=Github><i data-feather=github></i></a></li><li><a href=https://twitter.com/alen_vieira title=Twitter><i data-feather=twitter></i></a></li><li><a href=../../index.xml title=RSS><i data-feather=rss></i></a></li><li><a href=# class=scheme-toggle id=scheme-toggle></a></li></ul></nav></div><nav class=nav><ul class=flat><li><a href=../../>Home</a></li><li><a href=../../posts>Posts</a></li><li><a href=../../about>Sobre</a></li></ul></nav></div><div class=post><div class=post-header><div class=meta><div class=date><span class=day>30</span>
<span class=rest>Jan 2024</span></div></div><div class=matter><h1 class=title>Desenvolvendo Software com assistência de LLM</h1></div></div><div class=markdown><blockquote><p>Existe apenas uma luz na ciência, e acendê-la em qualquer lugar é iluminar todos os lugares. Isaac Asimov</p></blockquote><p>Conforme a reflexão do texto sobre Local-first, resolvi rumar no universo das LLMs rodando localmente para auxiliar no desenvolvimento de software. Mas, vamos por partes. Que diabos é uma LLM? Large language model ou LLM é um modelo de Inteligência Artificial(IA) na qual se tornou muito popular por ter bons resultados em diferentes áreas por meio de interações por chats. Entre as diversas áreas, ser uma assistente para os desenvolvedores de software terem uma melhor experiência no processo e focar mais na entrega do valor.</p><p>Há diversas ferramentas no mercado, algumas com planos gratuitos e outras mais robustas pagas, mas observei uma constante: a maioria precisa de interação com um modelo que está na nuvem. Prezando pela premissa local primeiro e que nem sempre podemos compartilhar códigos ou contextos do nosso problema sem quebrar alguma regra de privacidade, ou compliance, levando a considerar um estudo de algumas ferramentas que possam me ajudar a ter uma melhor produtividade quando estou desenvolvendo um software.</p><p>Estudando as soluções para isso, inferi que precisava, na verdade, precisaria de dois componentes:</p><ul><li>Um provedor local de modelos LLM: achei duas ferramentas legais, o <a href=https://lmstudio.ai/>LM Studio</a> e o <a href=https://ollama.ai/>Ollama</a> ambas ótimas. A verificar qual lhe agrada mais, ou a compatibilidade com seu sistema.</li><li>Uma ferramenta se integrar como interface, o caso com a IDE(Integrated Development Environment): Para Vscode e ferramentas da Jetbrains existe o <a href=https://continue.dev/>Continue</a>, que interage além de com os provedores locais também os hospedados na nuvem.</li></ul><p>Opa! Show! O que realmente posso fazer com esse conjunto?</p><ul><li>Autocompletar ou dar sugestões.</li><li>Pedir para tentar corrigir uma parte específica explicando o problema.</li><li>Tentar otimizar um determinado trecho do projeto.</li><li>Pegar algum payload de uma requisição/resposta para gerar uma estrutura inicial.</li><li>Gerar documentação ou explicação sobre algum trecho para fins de criação de uma especificação.</li></ul><p>Imaginação é o limite! Pode-se automatizar uma prévia de code review pela IA mediante uma customização de engenharia de prompt como, por <a href=https://github.com/mattzcarey/code-review-gpt/blob/main/packages/code-review-gpt/src/review/prompt/prompts.ts>exemplo</a>, do projeto &ldquo;<a href=https://github.com/mattzcarey/code-review-gpt>Code Review GPT</a>&rdquo;.</p><p>Pontos relevantes:</p><ul><li>Exige bastante da sua máquina. De preferência, use uma placa gráfica boa ou pelo menos 16 GB de RAM para rodar um CPU, entendendo que terá uma velocidade inferior.</li><li>Apesar de alguns modelos serem open source. Nem todos podem ser utilizados para trabalhos de fins comerciais, isso depende da licença utilizada pelo modelo. <a href=https://blog.continue.dev/what-llm-to-use/>Aqui</a> pode ter uma perspectiva dos modelos existentes.</li><li>Você terá que instalar, fazer configurações e customizações das ferramentas. Além de seleção de modelos e diversos testes para ver o que pode te atender.</li><li>É preciso saber balancear o contexto fornecido para não ser insuficiente ou demais, saber fornecer instruções precisa para evitar ambiguidades.</li><li>Lembre-se, é um assistente. A responsabilidade do código é sua, você sempre que avaliar as sugestões ou ter ponto crítico do que foi gerado.</li></ul><p>É isso! Vamos testar um assistente com LLM?</p></div><div class=tags></div><div id=disqus_thread></div><script type=text/javascript>(function(){if(window.location.hostname=="localhost")return;var t,e=document.createElement("script");e.type="text/javascript",e.async=!0,t="alenvieira",e.src="//"+t+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)})()</script><noscript>Please enable JavaScript to view the</a></noscript><a href=http://disqus.com/ class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div><div class="footer wrapper"><nav class=nav><div>Exceto onde indicado de outra forma, todos os conteúdos neste site essão licenciados sob licença <a class=subfoot href=https://creativecommons.org/licenses/by/4.0/ rel=license>Creative Commons Atribuição 4.0 Internacional</a></div><div>Desenvolvido com <a href=https://gohugo.io>Hugo</a>, adaptando o tema <a href=https://github.com/knadh/hugo-ink>Ink</a></div></nav></div><script>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-123-45","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script><script>feather.replace()</script></body></html>